{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a826bf",
   "metadata": {},
   "source": [
    "# Cellstates JAX vs CPU (Colab ready)\n",
    "\n",
    "This notebook installs `cellstates`, builds a tiny synthetic dataset, and times the JAX-accelerated vs. CPU gene contribution calculations. It is meant to be run in Google Colab; just set the runtime to GPU if you want to test JAX on GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be652cd4",
   "metadata": {},
   "source": [
    "**How to use**\n",
    "\n",
    "1. Run the install cell below (set `USE_GPU=True` only if your Colab runtime has a GPU).\n",
    "2. Generate the toy dataset (<=100 cells, <=200 genes) with a fixed seed.\n",
    "3. Benchmark `gene_contribution_table` (CPU) and `gene_contribution_table_jax` (JAX) with timings and parity checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install cellstates + JAX (run once per runtime)\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "USE_GPU = False  #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "def run(cmd, env=None):\n",
    "    print(f\"\n",
    ">>> {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, env=env)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed (exit {result.returncode}). See logs above.\")\n",
    "\n",
    "# Make sure build tooling is current\n",
    "run(\"python -m pip install --upgrade pip setuptools wheel\")\n",
    "\n",
    "# Core scientific stack; install first so cellstates can reuse the headers\n",
    "run(\"python -m pip install cython numpy pandas scipy\")\n",
    "\n",
    "jax_index = (\n",
    "    \"https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\"\n",
    "    if USE_GPU\n",
    "    else \"https://storage.googleapis.com/jax-releases/jax_releases.html\"\n",
    ")\n",
    "jax_pkg = \"jax[cuda12_pip]\" if USE_GPU else \"jax[cpu]\"\n",
    "run(f\"python -m pip install {jax_pkg} -f {jax_index}\")\n",
    "\n",
    "# Install cellstates using the already-installed numpy/Cython (helps avoid build isolation hiccups)\n",
    "build_env = os.environ.copy()\n",
    "build_env.setdefault(\"CC\", \"gcc\")\n",
    "build_env.setdefault(\"CXX\", \"g++\")\n",
    "run(\n",
    "    \"python -m pip install --no-build-isolation --no-cache-dir git+https://github.com/RemyNicolle/cellstates.git\",\n",
    "    env=build_env,\n",
    ")\n",
    "\n",
    "import jax\n",
    "from cellstates import available_jax_devices\n",
    "\n",
    "print(\"JAX version:\", jax.__version__)\n",
    "print(\"Detected JAX devices:\", jax.devices())\n",
    "print(\"cellstates import OK; available devices:\", available_jax_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c224a",
   "metadata": {},
   "source": [
    "## Generate a tiny synthetic dataset\n",
    "We keep it small (<=100 cells, <=200 genes) so it runs fast in Colab. A fixed seed ensures reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cellstates import Cluster, get_hierarchy_df\n",
    "\n",
    "SEED = 7\n",
    "GENES = 120\n",
    "CELLS = 90\n",
    "CLUSTERS = 3\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "cells_per_cluster = np.full(CLUSTERS, CELLS // CLUSTERS)\n",
    "cells_per_cluster[: CELLS % CLUSTERS] += 1\n",
    "\n",
    "base_rates = rng.gamma(shape=1.5, scale=1.0, size=(GENES, CLUSTERS))\n",
    "cluster_scales = np.linspace(0.7, 1.3, CLUSTERS)\n",
    "cluster_rates = base_rates * cluster_scales\n",
    "\n",
    "counts_parts = []\n",
    "labels = []\n",
    "for idx, n_cells in enumerate(cells_per_cluster):\n",
    "    lam = cluster_rates[:, idx : idx + 1]\n",
    "    counts_parts.append(rng.poisson(lam, size=(GENES, n_cells)))\n",
    "    labels.append(np.full(n_cells, idx, dtype=np.int32))\n",
    "\n",
    "counts = np.concatenate(counts_parts, axis=1).astype(np.int64)\n",
    "init_clusters = np.concatenate(labels)\n",
    "\n",
    "print(f\"Counts shape: {counts.shape} | cluster sizes: {np.bincount(init_clusters)}\")\n",
    "\n",
    "clst_cpu = Cluster(counts, c=init_clusters, max_clusters=init_clusters.max() + 1, seed=SEED)\n",
    "hierarchy, delta_ll = clst_cpu.get_cluster_hierarchy()\n",
    "hierarchy_df = get_hierarchy_df(hierarchy, delta_ll)\n",
    "print(f\"Hierarchy steps: {hierarchy_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106662e",
   "metadata": {},
   "source": [
    "## Benchmark CPU vs JAX gene contribution scores\n",
    "The first JAX call includes compilation; the second shows cached execution time. Both paths are compared for numerical parity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "from cellstates import (\n",
    "    Cluster,\n",
    "    available_jax_devices,\n",
    "    gene_contribution_table,\n",
    "    gene_contribution_table_jax,\n",
    "    jax_available,\n",
    ")\n",
    "\n",
    "\n",
    "def time_call(fn):\n",
    "    start = time.perf_counter()\n",
    "    out = fn()\n",
    "    return out, time.perf_counter() - start\n",
    "\n",
    "\n",
    "if not jax_available():\n",
    "    raise RuntimeError(\"JAX is not available; run the install cell first.\")\n",
    "\n",
    "device_preference = \"gpu\" if available_jax_devices(\"gpu\") else \"cpu\"\n",
    "\n",
    "# Fresh cluster for the JAX path so we avoid any state mutations\n",
    "clst_jax = Cluster(counts, c=init_clusters, max_clusters=init_clusters.max() + 1, seed=SEED)\n",
    "\n",
    "cpu_scores, cpu_time = time_call(lambda: gene_contribution_table(clst_cpu, hierarchy_df))\n",
    "\n",
    "jax_scores_first, jax_time_first = time_call(\n",
    "    lambda: gene_contribution_table_jax(\n",
    "        clst_jax,\n",
    "        hierarchy_df,\n",
    "        device=device_preference,\n",
    "        enable_x64=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "jax_scores_cached, jax_time_cached = time_call(\n",
    "    lambda: gene_contribution_table_jax(\n",
    "        clst_jax,\n",
    "        hierarchy_df,\n",
    "        device=device_preference,\n",
    "        enable_x64=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "max_diff = float(np.max(np.abs(cpu_scores - jax_scores_cached)))\n",
    "np.testing.assert_allclose(cpu_scores, jax_scores_cached, rtol=1e-9, atol=1e-9)\n",
    "\n",
    "print(f\"JAX devices detected: {jax.devices()}\")\n",
    "print(f\"Device used for JAX helper: {device_preference}\")\n",
    "print(f\"CPU gene_contribution_table: {cpu_time:.4f} s\")\n",
    "print(f\"JAX gene_contribution_table_jax (compile+run): {jax_time_first:.4f} s\")\n",
    "print(f\"JAX gene_contribution_table_jax (cached run): {jax_time_cached:.4f} s\")\n",
    "print(f\"Max |CPU - JAX| difference: {max_diff:.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
