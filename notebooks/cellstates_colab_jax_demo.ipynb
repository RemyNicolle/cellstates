{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a826bf",
   "metadata": {},
   "source": [
    "# Cellstates JAX vs CPU (Colab ready)\n",
    "\n",
    "This notebook installs `cellstates`, builds a tiny synthetic dataset, and times the JAX-accelerated vs. CPU gene contribution calculations. It is meant to be run in Google Colab; just set the runtime to GPU if you want to test JAX on GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be652cd4",
   "metadata": {},
   "source": [
    "**How to use**\n",
    "\n",
    "1. Run the install cell below (set `USE_GPU=True` only if your Colab runtime has a GPU).\n",
    "2. Generate the toy dataset (<=100 cells, <=200 genes) with a fixed seed.\n",
    "3. Benchmark `gene_contribution_table` (CPU) and `gene_contribution_table_jax` (JAX) with timings and parity checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install cellstates (Colab)\n",
    "# Clean any previous checkout so it doesn't shadow the installed package\n",
    "!rm -rf cellstates\n",
    "\n",
    "# 1) Make sure build tools and git are present\n",
    "!apt-get update -qq\n",
    "!apt-get install -y build-essential git\n",
    "\n",
    "# 2) Python deps that setup.py expects\n",
    "!pip install -q cython numpy scipy pandas matplotlib\n",
    "\n",
    "# 3) Clone your fork\n",
    "!git clone https://github.com/RemyNicolle/cellstates.git\n",
    "%cd cellstates\n",
    "\n",
    "# 4) Build and install via pip (handles the C extension build)\n",
    "!python -m pip install --no-build-isolation --no-cache-dir .\n",
    "\n",
    "# 5) Install JAX for the JAX benchmark (CPU by default; swap to cuda12_pip on GPU runtimes)\n",
    "!pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "# For GPU runtimes, instead run:\n",
    "# !pip install -q 'jax[cuda12_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# 6) Go back to the notebook root and remove the checkout so imports use site-packages\n",
    "%cd /content\n",
    "!rm -rf cellstates\n",
    "\n",
    "# 7) Verify the import resolves to the installed package\n",
    "import importlib.util, cellstates\n",
    "print(\"cellstates spec:\", importlib.util.find_spec(\"cellstates\"))\n",
    "from cellstates import Cluster, get_hierarchy_df\n",
    "print(\"Cluster import OK; module file:\", cellstates.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eba796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6c224a",
   "metadata": {},
   "source": [
    "## Generate a tiny synthetic dataset\n",
    "We keep it small (<=100 cells, <=200 genes) so it runs fast in Colab. A fixed seed ensures reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cellstates import Cluster, get_hierarchy_df\n",
    "\n",
    "SEED = 7\n",
    "GENES = 120\n",
    "CELLS = 90\n",
    "CLUSTERS = 3\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "cells_per_cluster = np.full(CLUSTERS, CELLS // CLUSTERS)\n",
    "cells_per_cluster[: CELLS % CLUSTERS] += 1\n",
    "\n",
    "base_rates = rng.gamma(shape=1.5, scale=1.0, size=(GENES, CLUSTERS))\n",
    "cluster_scales = np.linspace(0.7, 1.3, CLUSTERS)\n",
    "cluster_rates = base_rates * cluster_scales\n",
    "\n",
    "counts_parts = []\n",
    "labels = []\n",
    "for idx, n_cells in enumerate(cells_per_cluster):\n",
    "    lam = cluster_rates[:, idx : idx + 1]\n",
    "    counts_parts.append(rng.poisson(lam, size=(GENES, n_cells)))\n",
    "    labels.append(np.full(n_cells, idx, dtype=np.int32))\n",
    "\n",
    "counts = np.concatenate(counts_parts, axis=1).astype(np.int64)\n",
    "init_clusters = np.concatenate(labels)\n",
    "\n",
    "print(f\"Counts shape: {counts.shape} | cluster sizes: {np.bincount(init_clusters)}\")\n",
    "\n",
    "clst_cpu = Cluster(counts, c=init_clusters, max_clusters=init_clusters.max() + 1, seed=SEED)\n",
    "hierarchy, delta_ll = clst_cpu.get_cluster_hierarchy()\n",
    "hierarchy_df = get_hierarchy_df(hierarchy, delta_ll)\n",
    "print(f\"Hierarchy steps: {hierarchy_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106662e",
   "metadata": {},
   "source": [
    "## Benchmark CPU vs JAX gene contribution scores\n",
    "The first JAX call includes compilation; the second shows cached execution time. Both paths are compared for numerical parity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import jax\n",
    "\n",
    "from cellstates import (\n",
    "    Cluster,\n",
    "    available_jax_devices,\n",
    "    gene_contribution_table,\n",
    "    gene_contribution_table_jax,\n",
    "    jax_available,\n",
    ")\n",
    "\n",
    "\n",
    "def time_call(fn):\n",
    "    start = time.perf_counter()\n",
    "    out = fn()\n",
    "    return out, time.perf_counter() - start\n",
    "\n",
    "\n",
    "if not jax_available():\n",
    "    raise RuntimeError(\"JAX is not available; run the install cell first.\")\n",
    "\n",
    "device_preference = \"gpu\" if available_jax_devices(\"gpu\") else \"cpu\"\n",
    "\n",
    "# Fresh cluster for the JAX path so we avoid any state mutations\n",
    "clst_jax = Cluster(counts, c=init_clusters, max_clusters=init_clusters.max() + 1, seed=SEED)\n",
    "\n",
    "cpu_scores, cpu_time = time_call(lambda: gene_contribution_table(clst_cpu, hierarchy_df))\n",
    "\n",
    "jax_scores_first, jax_time_first = time_call(\n",
    "    lambda: gene_contribution_table_jax(\n",
    "        clst_jax,\n",
    "        hierarchy_df,\n",
    "        device=device_preference,\n",
    "        enable_x64=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "jax_scores_cached, jax_time_cached = time_call(\n",
    "    lambda: gene_contribution_table_jax(\n",
    "        clst_jax,\n",
    "        hierarchy_df,\n",
    "        device=device_preference,\n",
    "        enable_x64=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "max_diff = float(np.max(np.abs(cpu_scores - jax_scores_cached)))\n",
    "np.testing.assert_allclose(cpu_scores, jax_scores_cached, rtol=1e-9, atol=1e-9)\n",
    "\n",
    "print(f\"JAX devices detected: {jax.devices()}\")\n",
    "print(f\"Device used for JAX helper: {device_preference}\")\n",
    "print(f\"CPU gene_contribution_table: {cpu_time:.4f} s\")\n",
    "print(f\"JAX gene_contribution_table_jax (compile+run): {jax_time_first:.4f} s\")\n",
    "print(f\"JAX gene_contribution_table_jax (cached run): {jax_time_cached:.4f} s\")\n",
    "print(f\"Max |CPU - JAX| difference: {max_diff:.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
