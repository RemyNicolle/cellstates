{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6f7d20",
   "metadata": {},
   "source": [
    "# Cellstates JAX vs CPU (Colab ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca68508",
   "metadata": {},
   "source": [
    "**How to use**\n",
    "\n",
    "1. Run the install cell.\n",
    "2. Run the clustering synthetic data + PCA/k-means init.\n",
    "3. Run the clustering benchmark (CPU vs JAX devices).\n",
    "4. Run the hierarchy synthetic data + benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56042602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install cellstates (Colab)\n",
    "import os, subprocess, sys\n",
    "\n",
    "# Clean any previous checkout and any shadowing namespace dirs\n",
    "subprocess.run(\"find /content -maxdepth 2 -type d -name 'cellstates' -print -exec rm -rf {} +\", shell=True)\n",
    "subprocess.run(\"rm -rf /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 1) Build tools and git\n",
    "subprocess.check_call(\"apt-get update -qq\", shell=True)\n",
    "subprocess.check_call(\"apt-get install -y build-essential git\", shell=True)\n",
    "\n",
    "# 2) Python deps\n",
    "subprocess.check_call(\"pip install -q cython numpy scipy pandas matplotlib scikit-learn\", shell=True)\n",
    "\n",
    "# 3) Clone and install cellstates\n",
    "subprocess.check_call(\"git clone https://github.com/RemyNicolle/cellstates.git /content/cellstates_src\", shell=True)\n",
    "subprocess.check_call(\"python -m pip install --no-build-isolation --no-cache-dir /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 4) Install JAX with simple detection: TPU > GPU > CPU\n",
    "has_tpu = bool(os.environ.get(\"COLAB_TPU_ADDR\") or os.environ.get(\"TPU_NAME\"))\n",
    "has_gpu = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL).returncode == 0\n",
    "\n",
    "if has_tpu:\n",
    "    jax_cmd = \"pip install -q 'jax[tpu]' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\"\n",
    "    ret = subprocess.run(jax_cmd, shell=True)\n",
    "    if ret.returncode != 0:\n",
    "        print(\"TPU JAX install failed; falling back to CPU wheel\")\n",
    "        subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "elif has_gpu:\n",
    "    jax_cmd = \"pip install -q 'jax[cuda12_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\"\n",
    "    ret = subprocess.run(jax_cmd, shell=True)\n",
    "    if ret.returncode != 0:\n",
    "        print(\"CUDA JAX install failed; falling back to CPU wheel\")\n",
    "        subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "else:\n",
    "    subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "\n",
    "# 5) Return to root and clean clone to avoid shadowing\n",
    "subprocess.run(\"rm -rf /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 6) Verify import\n",
    "import importlib.util, cellstates\n",
    "print(\"cellstates spec:\", importlib.util.find_spec(\"cellstates\"))\n",
    "from cellstates import Cluster\n",
    "print(\"Cluster import OK; module file:\", cellstates.__file__)\n",
    "print(\"TPU detected:\", has_tpu)\n",
    "print(\"GPU detected:\", has_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import jax\n",
    "from cellstates import (\n",
    "    Cluster,\n",
    "    available_jax_devices,\n",
    "    run_greedy_partition_jax,\n",
    "    get_cluster_hierarchy_jax_from_counts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fbbe1",
   "metadata": {},
   "source": [
    "## Synthetic data for clustering benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7\n",
    "GENES_CLUST = 10\n",
    "CELLS_CLUST = 200\n",
    "CLUSTERS_CLUST = 20\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "cells_per_cluster = np.full(CLUSTERS_CLUST, CELLS_CLUST // CLUSTERS_CLUST)\n",
    "cells_per_cluster[: CELLS_CLUST % CLUSTERS_CLUST] += 1\n",
    "\n",
    "base_rates = rng.gamma(shape=1.5, scale=1.0, size=(GENES_CLUST, CLUSTERS_CLUST))\n",
    "cluster_scales = np.linspace(0.7, 1.3, CLUSTERS_CLUST)\n",
    "cluster_rates = base_rates * cluster_scales\n",
    "\n",
    "counts_parts = []\n",
    "labels = []\n",
    "for idx, n_cells in enumerate(cells_per_cluster):\n",
    "    lam = cluster_rates[:, idx : idx + 1]\n",
    "    counts_parts.append(rng.poisson(lam, size=(GENES_CLUST, n_cells)))\n",
    "    labels.append(np.full(n_cells, idx, dtype=np.int32))\n",
    "\n",
    "counts_clust = np.concatenate(counts_parts, axis=1).astype(np.int64)\n",
    "print('Clustering counts shape:', counts_clust.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468fb5a",
   "metadata": {},
   "source": [
    "## Init clusters with PCA + k-means (synthetic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "max_genes_for_pca = min(2000, counts_clust.shape[0])\n",
    "X = counts_clust\n",
    "if X.shape[0] > max_genes_for_pca:\n",
    "    gene_idx = np.random.default_rng(SEED).choice(X.shape[0], size=max_genes_for_pca, replace=False)\n",
    "    X = X[gene_idx]\n",
    "\n",
    "X_t = np.log1p(X).astype(np.float32)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_t)\n",
    "\n",
    "n_pcs = 30\n",
    "pca = PCA(n_components=min(n_pcs, X_scaled.shape[0], X_scaled.shape[1]), random_state=SEED)\n",
    "X_pca = pca.fit_transform(X_scaled.T)\n",
    "\n",
    "n_init_clusters = 200\n",
    "kmeans = KMeans(n_clusters=n_init_clusters, n_init=5, random_state=SEED, verbose=0)\n",
    "init_clusters = kmeans.fit_predict(X_pca).astype(np.int32)\n",
    "\n",
    "print(f\"Init clusters from k-means: {n_init_clusters}, counts per cluster (first 10): {np.bincount(init_clusters)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071e277",
   "metadata": {},
   "source": [
    "## Clustering benchmark (CPU vs JAX prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebab355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device preference: TPU > GPU > CPU\n",
    "if available_jax_devices(\"tpu\"):\n",
    "    device_preference = \"tpu\"\n",
    "elif available_jax_devices(\"gpu\"):\n",
    "    device_preference = \"gpu\"\n",
    "else:\n",
    "    device_preference = \"cpu\"\n",
    "\n",
    "cluster_chunk = 128\n",
    "candidate_topk = None\n",
    "sweeps = 3\n",
    "lam = np.full(counts_clust.shape[0], 0.5, dtype=np.float32)\n",
    "\n",
    "def time_call(fn):\n",
    "    start = time.perf_counter()\n",
    "    out = fn()\n",
    "    return out, time.perf_counter() - start\n",
    "\n",
    "# CPU (JAX on CPU)\n",
    "(cpu_clusters, cpu_moves, cpu_delta), cpu_time = time_call(\n",
    "    lambda: run_greedy_partition_jax(\n",
    "        counts_clust,\n",
    "        init_clusters,\n",
    "        lam=lam,\n",
    "        sweeps=sweeps,\n",
    "        device=\"cpu\",\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        cluster_chunk=cluster_chunk,\n",
    "        candidate_topk=candidate_topk,\n",
    "        seed=SEED,\n",
    "    )\n",
    ")\n",
    "\n",
    "# JAX on preferred device\n",
    "(jax_clusters, jax_moves, jax_delta), jax_time = time_call(\n",
    "    lambda: run_greedy_partition_jax(\n",
    "        counts_clust,\n",
    "        init_clusters,\n",
    "        lam=lam,\n",
    "        sweeps=sweeps,\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        cluster_chunk=cluster_chunk,\n",
    "        candidate_topk=candidate_topk,\n",
    "        seed=SEED,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"CPU sweeps: {sweeps}, moves: {cpu_moves}, total delta_LL: {cpu_delta:.3f}, time: {cpu_time:.3f} s\")\n",
    "print(f\"JAX sweeps ({device_preference}): moves: {jax_moves}, total delta_LL: {jax_delta:.3f}, time: {jax_time:.3f} s\")\n",
    "print(\"Cluster label sample (CPU first 10):\", cpu_clusters[:10])\n",
    "print(\"Cluster label sample (JAX first 10):\", jax_clusters[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f89720",
   "metadata": {},
   "source": [
    "## JAX stochastic partition (alternative to greedy)\n",
    "Samples a small set of candidate clusters per cell each sweep (always includes the current cluster) and accepts only improving moves. Use when K is large and you want lower memory than the full greedy scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd20ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellstates import stochastic_partition_jax\n",
    "\n",
    "# Limit proposals to keep memory low; set to None to sample all clusters\n",
    "proposals_per_cell = 8  # fixed size for JAX shapes  # lower to keep proposals fixed and small\n",
    "sweeps_alt = 3\n",
    "\n",
    "(alt_clusters, alt_moves, alt_delta), alt_time = time_call(\n",
    "    lambda: stochastic_partition_jax(\n",
    "        counts_clust,\n",
    "        init_clusters,\n",
    "        lam=lam,\n",
    "        sweeps=sweeps_alt,\n",
    "proposals_per_cell = 8  # fixed size for JAX shapes  # lower to keep proposals fixed and small\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        seed=SEED,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Alt stochastic: sweeps={sweeps_alt}, moves={alt_moves}, total delta_LL={alt_delta:.3f}, time={alt_time:.3f} s\")\n",
    "print(\"Cluster label sample (alt first 10):\", alt_clusters[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46041cb",
   "metadata": {},
   "source": [
    "## Synthetic data for hierarchy benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ca866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller hierarchy-friendly dataset\n",
    "GENES_HIER = 3000\n",
    "CELLS_HIER = 2000\n",
    "CLUSTERS_HIER = 150\n",
    "\n",
    "rng = np.random.default_rng(SEED + 1)\n",
    "cells_per_cluster_h = np.full(CLUSTERS_HIER, CELLS_HIER // CLUSTERS_HIER)\n",
    "cells_per_cluster_h[: CELLS_HIER % CLUSTERS_HIER] += 1\n",
    "\n",
    "base_rates_h = rng.gamma(shape=1.5, scale=1.0, size=(GENES_HIER, CLUSTERS_HIER))\n",
    "cluster_scales_h = np.linspace(0.7, 1.3, CLUSTERS_HIER)\n",
    "cluster_rates_h = base_rates_h * cluster_scales_h\n",
    "\n",
    "counts_parts_h = []\n",
    "labels_h = []\n",
    "for idx, n_cells in enumerate(cells_per_cluster_h):\n",
    "    lam_h = cluster_rates_h[:, idx : idx + 1]\n",
    "    counts_parts_h.append(rng.poisson(lam_h, size=(GENES_HIER, n_cells)))\n",
    "    labels_h.append(np.full(n_cells, idx, dtype=np.int32))\n",
    "\n",
    "counts_hier = np.concatenate(counts_parts_h, axis=1).astype(np.int64)\n",
    "init_clusters_hier = np.concatenate(labels_h)\n",
    "\n",
    "print('Hierarchy counts shape:', counts_hier.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caec079",
   "metadata": {},
   "source": [
    "## Hierarchy benchmark (CPU vs JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU hierarchy\n",
    "clst_cpu = Cluster(counts_hier, c=init_clusters_hier, max_clusters=init_clusters_hier.max() + 1, seed=SEED)\n",
    "\n",
    "start = time.perf_counter()\n",
    "hierarchy_cpu, delta_cpu = clst_cpu.get_cluster_hierarchy()\n",
    "cpu_hier_time = time.perf_counter() - start\n",
    "\n",
    "# Aggregate counts per cluster for JAX\n",
    "counts_per_cluster = np.zeros((counts_hier.shape[0], init_clusters_hier.max() + 1), dtype=np.int64)\n",
    "for idx in range(counts_per_cluster.shape[1]):\n",
    "    mask = init_clusters_hier == idx\n",
    "    if mask.any():\n",
    "        counts_per_cluster[:, idx] = counts_hier[:, mask].sum(axis=1)\n",
    "\n",
    "lam_hier = np.asarray(clst_cpu.dirichlet_pseudocounts, dtype=np.float32)\n",
    "\n",
    "pair_chunk_size = 50_000\n",
    "\n",
    "start = time.perf_counter()\n",
    "merges_jax, delta_jax = get_cluster_hierarchy_jax_from_counts(\n",
    "    counts_per_cluster,\n",
    "    lam_hier,\n",
    "    device=device_preference,\n",
    "    enable_x64=False,\n",
    "    dtype=jax.numpy.float32,\n",
    "    pair_chunk_size=pair_chunk_size,\n",
    ")\n",
    "jax_hier_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"CPU hierarchy: merges={len(hierarchy_cpu)}, time={cpu_hier_time:.3f} s\")\n",
    "print(f\"JAX hierarchy ({device_preference}): merges={len(merges_jax)}, time={jax_hier_time:.3f} s\")\n",
    "print(\"First 5 CPU merges:\", hierarchy_cpu[:5])\n",
    "print(\"First 5 JAX merges:\", merges_jax[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
