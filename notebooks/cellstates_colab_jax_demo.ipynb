{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6f7d20",
   "metadata": {},
   "source": [
    "# Cellstates JAX vs CPU (Colab ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca68508",
   "metadata": {},
   "source": [
    "**How to use**\n",
    "\n",
    "1. Run the install cell.\n",
    "2. Run the clustering synthetic data + PCA/k-means init.\n",
    "3. Run the clustering benchmark (CPU vs JAX devices).\n",
    "4. Run the hierarchy synthetic data + benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56042602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install cellstates (Colab)\n",
    "import os, subprocess, sys\n",
    "\n",
    "# Clean any previous checkout and any shadowing namespace dirs\n",
    "subprocess.run(\"find /content -maxdepth 2 -type d -name 'cellstates' -print -exec rm -rf {} +\", shell=True)\n",
    "subprocess.run(\"rm -rf /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 1) Build tools and git\n",
    "subprocess.check_call(\"apt-get update -qq\", shell=True)\n",
    "subprocess.check_call(\"apt-get install -y build-essential git\", shell=True)\n",
    "\n",
    "# 2) Python deps\n",
    "subprocess.check_call(\"pip install -q cython numpy scipy pandas matplotlib scikit-learn\", shell=True)\n",
    "\n",
    "# 3) Clone and install cellstates\n",
    "subprocess.check_call(\"git clone https://github.com/RemyNicolle/cellstates.git /content/cellstates_src\", shell=True)\n",
    "subprocess.check_call(\"python -m pip install --no-build-isolation --no-cache-dir /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 4) Install JAX with simple detection: TPU > GPU > CPU\n",
    "has_tpu = bool(os.environ.get(\"COLAB_TPU_ADDR\") or os.environ.get(\"TPU_NAME\"))\n",
    "has_gpu = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL).returncode == 0\n",
    "\n",
    "if has_tpu:\n",
    "    jax_cmd = \"pip install -q 'jax[tpu]' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\"\n",
    "    ret = subprocess.run(jax_cmd, shell=True)\n",
    "    if ret.returncode != 0:\n",
    "        print(\"TPU JAX install failed; falling back to CPU wheel\")\n",
    "        subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "elif has_gpu:\n",
    "    jax_cmd = \"pip install -q 'jax[cuda12_pip]' -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\"\n",
    "    ret = subprocess.run(jax_cmd, shell=True)\n",
    "    if ret.returncode != 0:\n",
    "        print(\"CUDA JAX install failed; falling back to CPU wheel\")\n",
    "        subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "else:\n",
    "    subprocess.check_call(\"pip install -q 'jax[cpu]' -f https://storage.googleapis.com/jax-releases/jax_releases.html\", shell=True)\n",
    "\n",
    "# 5) Return to root and clean clone to avoid shadowing\n",
    "subprocess.run(\"rm -rf /content/cellstates_src\", shell=True)\n",
    "\n",
    "# 6) Verify import\n",
    "import importlib.util, cellstates\n",
    "print(\"cellstates spec:\", importlib.util.find_spec(\"cellstates\"))\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import jax\n",
    "from cellstates import (\n",
    "    Cluster,\n",
    "    available_jax_devices,\n",
    "    stochastic_partition_jax,\n",
    "    run_gibbs_partition_jax,\n",
    "    get_cluster_hierarchy_jax_from_counts,\n",
    ")\n",
    "print(\"Cluster import OK; module file:\", cellstates.__file__)\n",
    "print(\"TPU detected:\", has_tpu)\n",
    "print(\"GPU detected:\", has_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fbbe1",
   "metadata": {},
   "source": [
    "## Synthetic data for clustering benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0435de",
   "metadata": {},
   "source": [
    "## Benchmark options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark options\n",
    "USE_JAX_GIBBS = False  # set False to skip JAX Gibbs variants\n",
    "GIBBS_SWEEPS = 3\n",
    "MCMC_STEPS = 50\n",
    "MCMC_TRIES = 400\n",
    "\n",
    "SEED = 7\n",
    "GENES_CLUST = 100\n",
    "CELLS_CLUST = 2000\n",
    "CLUSTERS_CLUST = 100\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "cells_per_cluster = np.full(CLUSTERS_CLUST, CELLS_CLUST // CLUSTERS_CLUST)\n",
    "cells_per_cluster[: CELLS_CLUST % CLUSTERS_CLUST] += 1\n",
    "\n",
    "base_rates = rng.gamma(shape=1.5, scale=1.0, size=(GENES_CLUST, CLUSTERS_CLUST))\n",
    "cluster_scales = np.linspace(0.7, 1.3, CLUSTERS_CLUST)\n",
    "cluster_rates = base_rates * cluster_scales\n",
    "\n",
    "counts_parts = []\n",
    "labels = []\n",
    "for idx, n_cells in enumerate(cells_per_cluster):\n",
    "    lam = cluster_rates[:, idx : idx + 1]\n",
    "    counts_parts.append(rng.poisson(lam, size=(GENES_CLUST, n_cells)))\n",
    "    labels.append(np.full(n_cells, idx, dtype=np.int32))\n",
    "\n",
    "counts_clust = np.concatenate(counts_parts, axis=1).astype(np.int64)\n",
    "print('Clustering counts shape:', counts_clust.shape)\n",
    "\n",
    "true_clusters = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468fb5a",
   "metadata": {},
   "source": [
    "## Init clusters with PCA + k-means (synthetic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "max_genes_for_pca = min(2000, counts_clust.shape[0])\n",
    "X = counts_clust\n",
    "if X.shape[0] > max_genes_for_pca:\n",
    "    gene_idx = np.random.default_rng(SEED).choice(X.shape[0], size=max_genes_for_pca, replace=False)\n",
    "    X = X[gene_idx]\n",
    "\n",
    "X_t = np.log1p(X).astype(np.float32)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_t)\n",
    "\n",
    "n_pcs = 30\n",
    "pca = PCA(n_components=min(n_pcs, X_scaled.shape[0], X_scaled.shape[1]), random_state=SEED)\n",
    "X_pca = pca.fit_transform(X_scaled.T)\n",
    "\n",
    "n_init_clusters = min(100, counts_clust.shape[1])\n",
    "kmeans = KMeans(n_clusters=n_init_clusters, n_init=5, random_state=SEED, verbose=0)\n",
    "init_clusters = kmeans.fit_predict(X_pca).astype(np.int32)\n",
    "\n",
    "print(f\"Init clusters from k-means: {n_init_clusters}, counts per cluster (first 10): {np.bincount(init_clusters)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071e277",
   "metadata": {},
   "source": [
    "## Clustering benchmark (CPU vs JAX prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebab355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device preference: TPU > GPU > CPU\n",
    "if available_jax_devices(\"tpu\"):\n",
    "    device_preference = \"tpu\"\n",
    "elif available_jax_devices(\"gpu\"):\n",
    "    device_preference = \"gpu\"\n",
    "else:\n",
    "    device_preference = \"cpu\"\n",
    "\n",
    "cluster_chunk = 128\n",
    "candidate_topk = None\n",
    "sweeps = 3\n",
    "lam = np.full(counts_clust.shape[0], 0.5, dtype=np.float32)\n",
    "\n",
    "# Cython CPU baseline (short MCMC)\n",
    "start = time.perf_counter()\n",
    "cl_baseline = Cluster(counts_clust, c=init_clusters, max_clusters=init_clusters.max() + 1, seed=SEED)\n",
    "try:\n",
    "    cl_baseline.biased_monte_carlo_sampling(N_steps=50, tries_per_step=400, min_index=0)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "cython_time = time.perf_counter() - start\n",
    "labels_cython = np.asarray(cl_baseline.clusters, dtype=np.int32)\n",
    "\n",
    "print(f\"Cython baseline time: {cython_time:.3f} s, clusters: {labels_cython.max()+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f89720",
   "metadata": {},
   "source": [
    "## JAX stochastic partition (alternative to greedy)\n",
    "Samples a small set of candidate clusters per cell each sweep (always includes the current cluster) and accepts only improving moves. Use when K is large and you want lower memory than the full greedy scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd20ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellstates import stochastic_partition_jax\n",
    "\n",
    "# fixed size for JAX shapes\n",
    "proposals_per_cell = 8\n",
    "sweeps_alt = 3\n",
    "\n",
    "start = time.perf_counter()\n",
    "labels_stochastic, alt_moves, alt_delta = stochastic_partition_jax(\n",
    "    counts_clust,\n",
    "    init_clusters,\n",
    "    lam=lam,\n",
    "    sweeps=sweeps_alt,\n",
    "    device=device_preference,\n",
    "    enable_x64=False,\n",
    "    dtype=jax.numpy.float32,\n",
    "    seed=SEED,\n",
    ")\n",
    "alt_time = time.perf_counter() - start\n",
    "print(f\"Stochastic ({device_preference}) time: {alt_time:.3f} s, moves: {alt_moves}, delta_LL: {alt_delta:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857efd77",
   "metadata": {},
   "source": [
    "## Likelihood and ARI comparison\n",
    "Compare partitions: initial k-means, JAX greedy (CPU/JAX), JAX stochastic, and Cython MCMC with/without stochastic warm start. ARI is measured against the synthetic ground-truth labels. Likelihoods are from the Cython Cluster for each labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96cd34",
   "metadata": {},
   "source": [
    "**Note:** likelihood reported is log-likelihood (natural log), higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from cellstates import Cluster, stochastic_partition_jax, run_gibbs_partition_jax\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Helper to compute log-likelihood for a given labeling (natural log)\n",
    "def partition_log_likelihood(labels):\n",
    "    cl = Cluster(counts_clust, c=labels, max_clusters=labels.max() + 1, seed=SEED)\n",
    "    return float(cl.total_likelihood)\n",
    "\n",
    "# Baseline partitions and timings\n",
    "baseline_parts = {\n",
    "    \"cython_mcmc\": (labels_cython, cython_time),\n",
    "    \"kmeans_init\": (init_clusters, 0.0),\n",
    "    \"stochastic\": (labels_stochastic, alt_time),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, (labels, t_val) in baseline_parts.items():\n",
    "    t_val = t_val or 0.0\n",
    "    rows.append({\n",
    "        \"partition\": name,\n",
    "        \"device\": device_preference,\n",
    "        \"log_likelihood\": partition_log_likelihood(labels),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": t_val,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": t_val,\n",
    "        \"n_clusters\": int(labels.max() + 1),\n",
    "    })\n",
    "\n",
    "# MCMC refinement from stochastic warm start\n",
    "cl = Cluster(counts_clust, c=labels_stochastic, max_clusters=labels_stochastic.max() + 1, seed=SEED)\n",
    "note = \"\"\n",
    "start = time.perf_counter()\n",
    "try:\n",
    "    cl.biased_monte_carlo_sampling(N_steps=MCMC_STEPS, tries_per_step=MCMC_TRIES, min_index=0)\n",
    "except RuntimeError as err:\n",
    "    note = f\"MCMC early stop: {err}\"\n",
    "mcmc_elapsed = time.perf_counter() - start\n",
    "refined = np.asarray(cl.clusters, dtype=np.int32)\n",
    "rows.append({\n",
    "    \"partition\": \"mcmc_warm_stochastic\",\n",
    "    \"device\": device_preference,\n",
    "    \"log_likelihood\": partition_log_likelihood(refined),\n",
    "    \"ari_true\": adjusted_rand_score(true_clusters, refined),\n",
    "    \"ari_cython\": adjusted_rand_score(labels_cython, refined),\n",
    "    \"refined\": True,\n",
    "    \"note\": note,\n",
    "    \"warm_time_s\": alt_time,\n",
    "    \"mcmc_time_s\": mcmc_elapsed,\n",
    "    \"total_time_s\": alt_time + mcmc_elapsed,\n",
    "    \"n_clusters\": int(refined.max() + 1),\n",
    "})\n",
    "\n",
    "if USE_JAX_GIBBS:\n",
    "    # JAX Gibbs from scratch\n",
    "    start = time.perf_counter()\n",
    "    labels_gibbs, gibbs_moves, gibbs_delta = run_gibbs_partition_jax(\n",
    "        counts_clust,\n",
    "        init_clusters,\n",
    "        lam=lam,\n",
    "        sweeps=GIBBS_SWEEPS,\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    gibbs_time = time.perf_counter() - start\n",
    "    rows.append({\n",
    "        \"partition\": \"jax_gibbs\",\n",
    "        \"device\": device_preference,\n",
    "        \"log_likelihood\": partition_log_likelihood(labels_gibbs),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels_gibbs),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels_gibbs),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": gibbs_time,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": gibbs_time,\n",
    "        \"n_clusters\": int(labels_gibbs.max() + 1),\n",
    "    })\n",
    "\n",
    "    # JAX Gibbs warm start from stochastic\n",
    "    start = time.perf_counter()\n",
    "    labels_gibbs_warm, gibbs_moves_warm, gibbs_delta_warm = run_gibbs_partition_jax(\n",
    "        counts_clust,\n",
    "        labels_stochastic,\n",
    "        lam=lam,\n",
    "        sweeps=GIBBS_SWEEPS,\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        seed=SEED + 1,\n",
    "    )\n",
    "    gibbs_warm_time = time.perf_counter() - start\n",
    "    rows.append({\n",
    "        \"partition\": \"jax_gibbs_warm_stochastic\",\n",
    "        \"device\": device_preference,\n",
    "        \"log_likelihood\": partition_log_likelihood(labels_gibbs_warm),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels_gibbs_warm),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels_gibbs_warm),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": alt_time + gibbs_warm_time,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": alt_time + gibbs_warm_time,\n",
    "        \"n_clusters\": int(labels_gibbs_warm.max() + 1),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "print(summary_df)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "summary_df.boxplot(column=\"log_likelihood\", by=\"partition\", rot=45)\n",
    "plt.suptitle(\"\")\n",
    "plt.title(\"Partition log-likelihood (natural log)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46041cb",
   "metadata": {},
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from cellstates import Cluster, stochastic_partition_jax, run_gibbs_partition_jax\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Helper to compute likelihood for a given labeling\n",
    "def partition_likelihood(labels):\n",
    "    cl = Cluster(counts_clust, c=labels, max_clusters=labels.max() + 1, seed=SEED)\n",
    "    return float(cl.total_likelihood)\n",
    "\n",
    "# Baseline partitions and timings\n",
    "baseline_parts = {\n",
    "    \"cython_mcmc\": (labels_cython, cython_time),\n",
    "    \"stochastic\": (labels_stochastic, alt_time),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, (labels, t_val) in baseline_parts.items():\n",
    "    t_val = t_val or 0.0\n",
    "    rows.append({\n",
    "        \"partition\": name,\n",
    "        \"device\": device_preference,\n",
    "        \"likelihood\": partition_likelihood(labels),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": t_val,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": t_val,\n",
    "        \"n_clusters\": int(labels.max() + 1),\n",
    "    })\n",
    "\n",
    "# MCMC refinement from stochastic warm start\n",
    "cl = Cluster(counts_clust, c=labels_stochastic, max_clusters=labels_stochastic.max() + 1, seed=SEED)\n",
    "note = \"\"\n",
    "start = time.perf_counter()\n",
    "try:\n",
    "    cl.biased_monte_carlo_sampling(N_steps=MCMC_STEPS, tries_per_step=MCMC_TRIES, min_index=0)\n",
    "except RuntimeError as err:\n",
    "    note = f\"MCMC early stop: {err}\"\n",
    "mcmc_elapsed = time.perf_counter() - start\n",
    "refined = np.asarray(cl.clusters, dtype=np.int32)\n",
    "rows.append({\n",
    "    \"partition\": \"mcmc_warm_stochastic\",\n",
    "    \"device\": device_preference,\n",
    "    \"likelihood\": partition_likelihood(refined),\n",
    "    \"ari_true\": adjusted_rand_score(true_clusters, refined),\n",
    "    \"ari_cython\": adjusted_rand_score(labels_cython, refined),\n",
    "    \"refined\": True,\n",
    "    \"note\": note,\n",
    "    \"warm_time_s\": alt_time,\n",
    "    \"mcmc_time_s\": mcmc_elapsed,\n",
    "    \"total_time_s\": alt_time + mcmc_elapsed,\n",
    "    \"n_clusters\": int(refined.max() + 1),\n",
    "})\n",
    "\n",
    "if USE_JAX_GIBBS:\n",
    "    # JAX Gibbs from scratch\n",
    "    start = time.perf_counter()\n",
    "    labels_gibbs, gibbs_moves, gibbs_delta = run_gibbs_partition_jax(\n",
    "        counts_clust,\n",
    "        init_clusters,\n",
    "        lam=lam,\n",
    "        sweeps=GIBBS_SWEEPS,\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    gibbs_time = time.perf_counter() - start\n",
    "    rows.append({\n",
    "        \"partition\": \"jax_gibbs\",\n",
    "        \"device\": device_preference,\n",
    "        \"likelihood\": partition_likelihood(labels_gibbs),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels_gibbs),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels_gibbs),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": gibbs_time,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": gibbs_time,\n",
    "        \"n_clusters\": int(labels_gibbs.max() + 1),\n",
    "    })\n",
    "\n",
    "    # JAX Gibbs warm start from stochastic\n",
    "    start = time.perf_counter()\n",
    "    labels_gibbs_warm, gibbs_moves_warm, gibbs_delta_warm = run_gibbs_partition_jax(\n",
    "        counts_clust,\n",
    "        labels_stochastic,\n",
    "        lam=lam,\n",
    "        sweeps=GIBBS_SWEEPS,\n",
    "        device=device_preference,\n",
    "        enable_x64=False,\n",
    "        dtype=jax.numpy.float32,\n",
    "        seed=SEED + 1,\n",
    "    )\n",
    "    gibbs_warm_time = time.perf_counter() - start\n",
    "    rows.append({\n",
    "        \"partition\": \"jax_gibbs_warm_stochastic\",\n",
    "        \"device\": device_preference,\n",
    "        \"likelihood\": partition_likelihood(labels_gibbs_warm),\n",
    "        \"ari_true\": adjusted_rand_score(true_clusters, labels_gibbs_warm),\n",
    "        \"ari_cython\": adjusted_rand_score(labels_cython, labels_gibbs_warm),\n",
    "        \"refined\": False,\n",
    "        \"note\": \"\",\n",
    "        \"warm_time_s\": alt_time + gibbs_warm_time,\n",
    "        \"mcmc_time_s\": 0.0,\n",
    "        \"total_time_s\": alt_time + gibbs_warm_time,\n",
    "        \"n_clusters\": int(labels_gibbs_warm.max() + 1),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "print(summary_df)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "summary_df.boxplot(column=\"likelihood\", by=\"partition\", rot=45)\n",
    "plt.suptitle(\"\")\n",
    "plt.title(\"Partition likelihoods\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ca866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU hierarchy (reuse clustering synthetic data)\n",
    "counts_hier = counts_clust\n",
    "init_clusters_hier = init_clusters\n",
    "clst_cpu = Cluster(counts_hier, c=init_clusters_hier, max_clusters=init_clusters_hier.max() + 1, seed=SEED)\n",
    "\n",
    "start = time.perf_counter()\n",
    "hierarchy_cpu, delta_cpu = clst_cpu.get_cluster_hierarchy()\n",
    "cpu_hier_time = time.perf_counter() - start\n",
    "\n",
    "# Aggregate counts per cluster for JAX\n",
    "counts_per_cluster = np.zeros((counts_hier.shape[0], init_clusters_hier.max() + 1), dtype=np.int64)\n",
    "for idx2 in range(counts_per_cluster.shape[1]):\n",
    "    mask = init_clusters_hier == idx2\n",
    "    if mask.any():\n",
    "        counts_per_cluster[:, idx2] = counts_hier[:, mask].sum(axis=1)\n",
    "\n",
    "lam_hier = np.asarray(clst_cpu.dirichlet_pseudocounts, dtype=np.float32)\n",
    "\n",
    "pair_chunk_size = 50_000\n",
    "\n",
    "start = time.perf_counter()\n",
    "merges_jax, delta_jax = get_cluster_hierarchy_jax_from_counts(\n",
    "    counts_per_cluster,\n",
    "    lam_hier,\n",
    "    device=device_preference,\n",
    "    enable_x64=False,\n",
    "    dtype=jax.numpy.float32,\n",
    "    pair_chunk_size=pair_chunk_size,\n",
    ")\n",
    "jax_hier_time = time.perf_counter() - start\n",
    "\n",
    "import pandas as pd\n",
    "hier_rows = [\n",
    "    {\n",
    "        \"method\": \"cpu_hierarchy\",\n",
    "        \"merges\": len(hierarchy_cpu),\n",
    "        \"time_s\": cpu_hier_time,\n",
    "    },\n",
    "    {\n",
    "        \"method\": f\"jax_hierarchy_{device_preference}\",\n",
    "        \"merges\": len(merges_jax),\n",
    "        \"time_s\": jax_hier_time,\n",
    "    },\n",
    "]\n",
    "hier_df = pd.DataFrame(hier_rows)\n",
    "print(hier_df)\n",
    "\n",
    "print(f\"CPU hierarchy: merges={len(hierarchy_cpu)}, time={cpu_hier_time:.3f} s\")\n",
    "print(f\"JAX hierarchy ({device_preference}): merges={len(merges_jax)}, time={jax_hier_time:.3f} s\")\n",
    "print(\"First 5 CPU merges:\", hierarchy_cpu[:5])\n",
    "print(\"First 5 JAX merges:\", merges_jax[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caec079",
   "metadata": {},
   "source": [
    "## Hierarchy benchmark (CPU vs JAX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
